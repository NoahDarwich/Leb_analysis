{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import tempfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "import subprocess\n",
    "\n",
    "import PyPDF2\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../Data/Final_Thawra.xlsx', header=1, index_col='recordnumber')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['drive'] = ''\n",
    "# for _, row in df.iterrows():\n",
    "#     for i in row.index:\n",
    "#         if str(row[i]).startswith('https://drive.google'):\n",
    "#             df.at[_,'drive'] = row[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_content):\n",
    "  resource_manager = PDFResourceManager()\n",
    "  fake_file_handle = io.StringIO()\n",
    "  converter = TextConverter(resource_manager, fake_file_handle)\n",
    "  page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "\n",
    "  with io.BytesIO(pdf_content) as fh:\n",
    "    for page in PDFPage.get_pages(fh,\n",
    "                                  caching=True,\n",
    "                                  check_extractable=True):\n",
    "      page_interpreter.process_page(page)\n",
    "\n",
    "    text = fake_file_handle.getvalue()\n",
    "\n",
    "  # close open handles\n",
    "  converter.close()\n",
    "  fake_file_handle.close()\n",
    "\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    # fh = io.BytesIO()\n",
    "    # downloader = MediaIoBaseDownload(fh, response)\n",
    "    # pdf_content = fh.getvalue()\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            for page_num in range(reader.numPages):\n",
    "                page = reader.getPage(page_num)\n",
    "                text += page.extractText()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file_id(url):\n",
    "    pattern = r\"open\\?id=([\\w-]+)\"\n",
    "    match = re.search(pattern, url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        pattern = r\"file/d/([\\w-]+)\"\n",
    "        match = re.search(pattern, url)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(pdf_text):\n",
    "    \n",
    "    #cleaned_text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', pdf_text)\n",
    "    \n",
    "    #cleaned_text = re.sub(r'[^؀-ۿ\\s]', '', pdf_text)\n",
    "    cleaned_text = re.sub(r'http\\S+', '', pdf_text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'%[0-9a-fA-F]{2}', '', cleaned_text)\n",
    "    cleaned_text = cleaned_text.replace('\\n',' ').replace('ـ', '').replace('�', '')\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Google Sheets API credentials\n",
    "scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
    "creds_sheet = ServiceAccountCredentials.from_json_keyfile_name('leba-375419-92c3baf53205.json', scope)\n",
    "client = gspread.authorize(creds_sheet)\n",
    "\n",
    "# Fetch PDF URLs from Google Sheets document\n",
    "spreadsheet_key = '1xyQe3vgYKGl_hcPa1MOEn970xjTUirEUq_ewfiGjLRs'\n",
    "sheet_name = 'Main'\n",
    "worksheet = client.open_by_key(spreadsheet_key).worksheet(sheet_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds_drive = ServiceAccountCredentials.from_json_keyfile_name('leba-375419-92c3baf53205.json',\n",
    "                                                         scopes=['https://www.googleapis.com/auth/drive'])\n",
    "service_drive = build('drive', 'v3', credentials=creds_drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = worksheet.col_values(161)\n",
    "urls = [x for x in urls if len(x) > 6] \n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = [x for x in urls if x]\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://drive.google.com/open?id=18oW7JuXmtxhOL6GJZH27CB6KS1isMbu5&authuser=amrdukmak%40gmail.com&usp=drive_fs',\n",
       " 'https://drive.google.com/file/d/1DnP3136ezQuns9E9At4swskZHdpSCZgG/view?usp=share_link',\n",
       " 'https://drive.google.com/file/d/1fLBkFDRUtgoEaGIx_gEXWuZdTTJ1cKBk/view?usp=share_link',\n",
       " 'https://drive.google.com/file/d/1LoeXUXlFzI5KDJxhHZWc8MzZgJD2U7ng/view?usp=share_link',\n",
       " 'https://drive.google.com/file/d/1WysX1w13fDSzSKa-t0Cd7x0HC6n67NJB/view?usp=sharing',\n",
       " 'https://drive.google.com/file/d/1VIVZRvsKVRDsizc6IwAZMsur4e4H8Qi6/view?usp=sharing',\n",
       " 'https://drive.google.com/file/d/1vZgAlr77hiPuSvXCVHH-21m_zselLcLF/view?usp=sharing',\n",
       " 'https://drive.google.com/file/d/1kSgelIxklsHEFh3rn7YnoyqpT7NEFJtn/view?usp=sharing',\n",
       " 'https://drive.google.com/open?id=1wiX2A9_Xc3mUOQOxAU7Oag_ep2xeThI4&authuser=amrdukmak%40gmail.com&usp=drive_fs',\n",
       " 'https://drive.google.com/file/d/1FZboNDY8sUeP-Ec7S9dHhfPnR3EB4yu9/view?usp=sharing']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = list(dict.fromkeys(urls))\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 https://drive.google.com/open?id=18oW7JuXmtxhOL6GJZH27CB6KS1isMbu5&authuser=amrdukmak%40gmail.com&usp=drive_fs\n",
      "20.0 https://drive.google.com/file/d/1DnP3136ezQuns9E9At4swskZHdpSCZgG/view?usp=share_link\n",
      "30.0 https://drive.google.com/file/d/1fLBkFDRUtgoEaGIx_gEXWuZdTTJ1cKBk/view?usp=share_link\n",
      "40.0 https://drive.google.com/file/d/1LoeXUXlFzI5KDJxhHZWc8MzZgJD2U7ng/view?usp=share_link\n",
      "50.0 https://drive.google.com/file/d/1WysX1w13fDSzSKa-t0Cd7x0HC6n67NJB/view?usp=sharing\n",
      "60.0 https://drive.google.com/file/d/1VIVZRvsKVRDsizc6IwAZMsur4e4H8Qi6/view?usp=sharing\n",
      "70.0 https://drive.google.com/file/d/1vZgAlr77hiPuSvXCVHH-21m_zselLcLF/view?usp=sharing\n",
      "80.0 https://drive.google.com/file/d/1kSgelIxklsHEFh3rn7YnoyqpT7NEFJtn/view?usp=sharing\n",
      "90.0 https://drive.google.com/open?id=1wiX2A9_Xc3mUOQOxAU7Oag_ep2xeThI4&authuser=amrdukmak%40gmail.com&usp=drive_fs\n",
      "100.0 https://drive.google.com/file/d/1FZboNDY8sUeP-Ec7S9dHhfPnR3EB4yu9/view?usp=sharing\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for url in urls:\n",
    "    file_id = extract_file_id(url)\n",
    "    if file_id:\n",
    "        try:\n",
    "            request = service_drive.files().get_media(fileId=file_id)\n",
    "            fh = io.BytesIO()\n",
    "            downloader = MediaIoBaseDownload(fh, request)\n",
    "            done = False\n",
    "            while done is False:\n",
    "                status, done = downloader.next_chunk()\n",
    "                #print(\"Download %d%%.\" % int(status.progress() * 100))\n",
    "            pdf_content = fh.getvalue()\n",
    "            with open('new.pdf', 'wb') as f:\n",
    "                f.write(pdf_content)\n",
    "\n",
    "            pdf = PyPDF2.PdfReader(open('new.pdf', 'rb'))\n",
    "            \n",
    "            pdf_text = \"\"\n",
    "            for page in range(pdf._get_num_pages()):\n",
    "                text = pdf.pages[page].extract_text()\n",
    "                pdf_text = pdf_text + ''.join(text)\n",
    "                \n",
    "            cleaned_text = clean_text(pdf_text)\n",
    "            cell = worksheet.find(url)\n",
    "            worksheet.update_cell(cell.row, 163, pdf_text)\n",
    "            os.remove('new.pdf')\n",
    "            count += 1\n",
    "            print((count * 100)/len(urls) , url)\n",
    "            \n",
    "        except:\n",
    "            print('error')\n",
    "            cell = worksheet.find(url)\n",
    "            worksheet.update_cell(cell.row, 163, 'error')\n",
    "    else:\n",
    "        cell = worksheet.find(url)\n",
    "        worksheet.update_cell(cell.row, 163, 'NOT_FOUND')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in bad_urls:\n",
    "    file_id = extract_file_id(url)\n",
    "    print(file_id)\n",
    "    if file_id:\n",
    "        try:\n",
    "            request = service_drive.files().get_media(fileId=file_id)\n",
    "            fh = io.BytesIO()\n",
    "            downloader = MediaIoBaseDownload(fh, request)\n",
    "            done = False\n",
    "            while done is False:\n",
    "                status, done = downloader.next_chunk()\n",
    "                #print(\"Download %d%%.\" % int(status.progress() * 100))\n",
    "            pdf_content = fh.getvalue()\n",
    "            with open('new.pdf', 'wb') as f:\n",
    "                f.write(pdf_content)\n",
    "\n",
    "            pdf = PyPDF2.PdfReader(open('new.pdf', 'rb'))\n",
    "            pdf_text = \"\"\n",
    "\n",
    "            pdf_text = pdf.pages[0].extract_text()\n",
    "            text = clean_text(pdf_text)\n",
    "            cell = worksheet.find(url)\n",
    "            worksheet.update_cell(cell.row, 167, text)\n",
    "            os.remove('new.pdf')\n",
    "            count += 1\n",
    "            print((count * 100)/len(urls) , url)\n",
    "        except:\n",
    "            print('error')\n",
    "            bad_urls.append(url)\n",
    "            worksheet.update_cell(cell.row, 167, 'error')\n",
    "    else:\n",
    "        cell = worksheet.find(url)\n",
    "        worksheet.update_cell(cell.row, 167, 'NOT_FOUND')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://drive.google.com/open?id=12wiwto6X1NpzNYBDjqnxdsuw9YjE-7Cb&authuser=amrdukmak%40gmail.com&usp=drive_fs'\n",
    "\n",
    "file_id = extract_file_id(url)\n",
    "print(url)\n",
    "print(file_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    pdf_text = subprocess.check_output(['python', 'pdf_text_extractor.py', url])\n",
    "    # Update Google Sheets with the extracted text\n",
    "    cell = worksheet.find(url)\n",
    "    worksheet.update_cell(cell.row, cell.col -2, pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_id = extract_file_id(urls[444])\n",
    "# results = service_drive.files().get(fileId=file_id).execute()\n",
    "\n",
    "# request = service_drive.files().export_media(fileId=results.get('id'), mimeType=results.get('mimeType'))\n",
    "\n",
    "#request = service_drive.files().get_media(fileId=file_id)\n",
    "# fh = io.BytesIO()\n",
    "# downloader = MediaIoBaseDownload(fh, request)\n",
    "# #print(request.headers)\n",
    "# with open('new.pdf', 'wb') as f:\n",
    "#     f.write(fh.getvalue())\n",
    "\n",
    "# pdf = PyPDF2.PdfReader(open('new.pdf', 'rb'))\n",
    "# pdf_text = \"\"\n",
    "\n",
    "# for page in range(pdf.getNumPages()):\n",
    "#     pdf_text += pdf.getPage(page).extractText()\n",
    "# print(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = requests.get(urls[300])\n",
    "# print(response.headers)\n",
    "\n",
    "#fh = io.BytesIO(response.content)\n",
    "#downloader = MediaIoBaseDownload(fh, response.content)\n",
    "    \n",
    "# pdf_content = fh.read()\n",
    "# pdf_content\n",
    "# with open('new.pdf', 'wb') as f:\n",
    "#     f.write(pdf_content)\n",
    "    \n",
    "\n",
    "# # pdf_content = response.content\n",
    "# print(pdf_content)\n",
    "# # with open('new.pdf', 'wb') as f:\n",
    "# #     f.write(pdf_content)\n",
    "\n",
    "\n",
    "# pdf = PyPDF2.PdfReader(open('new.pdf', 'rb'))\n",
    "# pdf_text = \"\"\n",
    "# for page in range(pdf.getNumPages()):\n",
    "#     pdf_text += pdf.getPage(page).extractText()\n",
    "\n",
    "# # # Print the extracted text\n",
    "# print(pdf_text)\n",
    "\n",
    "# # fh = io.BytesIO()\n",
    "# # downloader = MediaIoBaseDownload(fh, pdf_content)\n",
    "# # pdf_content = fh.getvalue()\n",
    "# # with open('new.pdf', 'wb') as f:\n",
    "# #         f.write(pdf_content)\n",
    "\n",
    "# # pdf = PyPDF2.PdfReader(open('new.pdf', 'rb'))\n",
    "# # pdf_text = extract_text_from_pdf('new.pdf')\n",
    "# # pdf_text\n",
    "# # # temp_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from each PDF using the local Python function\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
